# translate-cognition

Generation of features and preparation for preprocessing of language text to optimize translation to a target language. The languages processed by the included modules are English and Mandarin Chinese. Sources for these languages, for development purposes, are as follows:

- [English News Text Treebank: Penn Treebank Revised](https://catalog.ldc.upenn.edu/LDC2015T13)
- [Chinese Treebank 8.0](https://catalog.ldc.upenn.edu/LDC2013T21)

The Chinese treebank text require preprocessing in order to provide tagged, bracketed text in the same format as the English News Text Treebank. To that end, the [TreebankPreprocessing] should be used for this preprocessing.

The English News Text Treebank contains folder eng\_news\_txt\_tbnk-ptb\_revised which should be unpackaged as a subdirectory of the data folder indicated at the command line, below.

The Chinese Treebank should be preprocessed using [TreebankPreprocessing](https://github.com/hankcs/TreebankPreprocessing), with the preprocessed result stored in ./ctb5.1\_preproc under the data folder. Note that while feature generation is functional for both treebanks, the main development work has focused on preprocessing the English text for later translation to English.


## Sources

The following sources are included in this repository:

| Module | Function |
| ------ | -------- |
| GenerateFeatures.py | Parse treebank files and generate features. This module uses NLTK Tree and ParentedTree to navigate bracketed parse trees and collect features. This module requires two command line parameters. First, either "ctb" or "ptb" to indicate whether the Chinese or English treebank files are to be processed to produce features. Second, an option such as "--data \<data-folder\>" (replacing "\<data-folder\>") with the folder location with the two required treebanks. |
| node\_feature\_parser.py | This is a class used for parsing nltk.ParentedTrees for feature generation. It is used in GenerateFeatures.py |
| crf\_mock.py | This is a mockup of a primitive attempt to classify words in a segment as before or after a head word. The point of this was as a development tool without the use of the CollinsHeadFinder or SemanticHeadFinder, neither of which are yet used in this source tree. It requires ./tools/stanford-parser-full-2018-10-17 under the folder in which it is executed, and jars stanford-parser-3.9.2-models.jar and stanford-parser.jar in that folder. |
|ReWriteExamples.py | This was initial work on reading the features JSON files generated by GenerateFeatures.py into a tensorflow graph. It is currently not functioning correctly. |
| ReorderCRF.py | This was another past POC and not currently functioning, due to the refactoring of the features generation in GenerateFeatures.py |

 






